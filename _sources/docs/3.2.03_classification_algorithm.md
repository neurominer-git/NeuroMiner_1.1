### Classification algorithm {#3.2.03_classification_algorithm}

Support Vector methodologies are the base of the evaluation core of
NeuroMiner, other methods such as k-Nearest Neighbors and Random Forests
are also available. In this distribution we rely on the LIBSVM
/LIBLINEAR toolboxes for the implementation of support vector based
classifiers and regressors. matLearn is also now introduced and requires
the Statistics and Optimization Toolbox.

NeuroMiner interface will change according to the evaluation type
selected in the data input process, two operation modes are implemented:
Classification and Regression. The following will refer to each of these
separately.

#### Classification mode {#3.2.03.1_classification_algorithm}

In this section we will describe the set up of **Classifiers** in
Neurominer.

##### Define prediction performance criterion {#3.2.03.1.1_performance_criterion}

During machine learning, models will be optimised and evaluated based on
a criterion. For classification problems NeuroMiner provides the
following performances measures:

1.  Accuracy: sum(EÂ =P)\*100/N
    [ACC](https://en.wikipedia.org/wiki/Accuracy_and_precision)

2.  True Positive Rate: e.g. for one-class SVM [True Positive Rate: e.g.
    for one-class
    SVM](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)

3.  False Positive Rate: e.g. for one-class SVM [False Positive Rate:
    e.g. for one-class
    SVM](https://en.wikipedia.org/wiki/False_positive_rate)

4.  Positive Predictive Value: e.g. for one class SVM [Positive
    Predictive Value: e.g. for one class
    SVM](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values)

5.  Matthews Correlation Coefficient:\
    (TP\*TN-FP\*FN)/sqrt((TP+FP)\*(TP+FN)\*(TN+FP)\*(TN+FN))\
    [MCC](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient)Matthews
    Correlation Coefficient

6.  Area-Under-the-Curve
    [ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)Area-Under-the-Curve

7.  Geometric Mean: sqrt(PPV\*True Positive Rate) [Geometric
    Mean](https://en.wikipedia.org/wiki/Geometric_mean)

8.  Balanced Accuracy: (sensitivity+specificity) / 2)
    [BAC](https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification)Balanced
    Accuracy

9.  Enhanced Balanced Accuracy: (sensitivity\*specificity)/100)

10. F-score: (1+beta2)\*precision\*recall /
    (beta2\*(precision+recall)) \* 100
    [F-score](https://en.wikipedia.org/wiki/F1_score)

11. Prognostic Summary Index: PPV+NPV-100

12. Number Needed to Predict: 1/PPV

Notes: E, expected; P, predicted; TP, true positive; TN, true negative;
FP, false positive; FN, false negative; PPV, positive predictive value;
NPV, negative predictive value.

Each of these performance measures can have an effect on the resulting
model and is dependent on the analysis that is being conducted. For
example, simple accuracy is useful when it doesn't matter if sensitivity
and specificity needs to be balanced (e.g., if sensitivity could be very
high and specificity very low). However, if there are unequal sample
sizes then this can lead to very unbalanced sensitivity and specificity
that is an artifact of sample size, which can be corrected by using
balanced accuracy (BAC).

##### Configure learning algorithm {#3.2.03.1.2_learning_algorithm}

Learning algorithm to be used for the **classification** analysis. Each
algorithm has a particular set of parameters that are described in the
respective distributions. In general defaults are provided.

1.  SVM -- [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)

2.  SVM/LR -- [LIBLINEAR](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)

3.  RVM / BAYES -- [Mike Tipping's
    implementation](https://github.com/ipsorakis/mRVMs)

4.  Local Learning -- [Akbas fuzzy k-Nearest Neighbors
    (fKNN)](https://de.mathworks.com/matlabcentral/fileexchange/13358-fuzzy-knn)

5.  Univariate -- GLM Logistic Regression [MATLAB
    glmfit](https://de.mathworks.com/help/stats/glmfit.html)

6.  Decision Tree -- [MATLAB Statistics Toolbox implementation of the
    Decision Tree
    algorithm](http://de.mathworks.com/help/stats/classification-trees-and-regression-trees.html)

7.  Random Forest -- [Abhishek Jaiantilal's fast Random Forest algorithm
    for MATLAB
    ](https://de.mathworks.com/matlabcentral/fileexchange/31036-random-forest)

8.  matLearn --
    [matLearn](https://www.cs.ubc.ca/~schmidtm/Software/matLearn.html).
    This only works when users have the Statistics and Optimization
    Toolbox

9.  GLMNET -- [Hastie's library for LASSO/Elastic-net regularized
    GLM](https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html)

10. Gradient Boost -- [Carlos Becker's gradient boosting
    algorithm](https://sites.google.com/site/carlosbecker/resources/gradient-boosting-boosted-trees)

Once one of these option is selected, you will have to define a number
of other settings that are specific to the algorithm and can be found in
the respective references above. In the following, we present the
options that are available for SVM.

**SVM options**

The following options will appear when SVM is selected:

1 : LIBSVM version \[ 3.12 \]\
2 : Classifier type \[ C-SVC (L1-regul.) \]\
3 : Probability estimation using Platt's method \[ no \]\
4 : Cache size \[ 500 MB \]\
5 : Termination criterion \[ 0.001 \]\
6 : Shrinking heuristics \[ yes \]\
7 : Weighting of hyperplane in uneven group sizes \[ no \]\
8 : Case-level weighting vector \[ Case weighting not activated \]\
Each of the first 6 options are standard options within the LIBSVM
toolbox [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/). However,
NeuroMiner also offers hyperplane weighting in uneven group sizes. This
is an important option because support vector machines work effectively
in circumstances with balanced samples of class examples but suboptimal
results can emerge when there are unequal class proportions; i.e., the
hyperplane can be biased towards a correct classification of the
majority class, thus resulting in poor classification performance in the
minority class. This is called an imbalanced learning problem. To
account for this problem class-weighted SVM can be used. Rather than
having equal misclassification penalties (C values) for all individuals
this approach corrects for imbalanced learning by increasing the
misclassification penalty in the minority class. Specifically each C
parameter for each class is multiplied by the inverse ratio of the
training class sizes. To optimise the serach for optimal class weights,
you can also introduce an additional hyperparameter that multiplies the
inverse ratio by a scaling factor for each class prior to the
multiplication of the C parameter. This can be defined when the learning
algorithm parameters settings in section
[\[3.2.04_learning_algorithm_parameters\]](#3.2.04_learning_algorithm_parameters){reference-type="ref"
reference="3.2.04_learning_algorithm_parameters"}. Similarly, option 8
allows you to weight the hyperplane based on a vector of weighting
parameters that you have defined. This will work similarly to the above,
but it will use the parameters entered rather than the group sizes.

Once these options are selected, NeuroMiner will progress to the next
menu to define the kernel type.

##### Define kernel type

Define whether the algorithm will use a linear or non-linear kernel
[Kernel](https://en.wikipedia.org/wiki/Support_vector_machine#Nonlinear_classification).
This will display the following options:

1: Linear\
2: Polynomial\
3: RBF (Gaussian)\
4: Sigmoid

Once these settings are defined, then you will be directed back to the
main menu for this section and you can proceed to the main menu and then
can configure the learning algorithm in section
[\[3.2.04_learning_algorithm_parameters\]](#3.2.04_learning_algorithm_parameters){reference-type="ref"
reference="3.2.04_learning_algorithm_parameters"}.

#### Regression mode {#3.2.03.1_regression_algorithm}

If you have defined a regression framework during data input (see
section
[\[mainmenu_3.1_input_data\]](#mainmenu_3.1_input_data){reference-type="ref"
reference="mainmenu_3.1_input_data"}) then a different menu will appear
as follows.

##### Define prediction performance criterion {#3.2.03.2.1_performance_criterion}

Performance criteria play a major roles in model evaluation and
optimization, for regression NM provides 5 performances measures:

1.  Mean Squared Error
    [MSE](https://en.wikipedia.org/wiki/Mean_squared_error)

2.  Normalized Root of Mean Squared Deviation
    [NRMSD](https://en.wikipedia.org/wiki/Root-mean-square_deviation#Normalized_root-mean-square_deviation)

3.  Squared Correlation Coefficient
    [R^2^](https://en.wikipedia.org/wiki/Coefficient_of_determination#As_squared_correlation_coefficient)

4.  Correlation Coefficient
    [CC](https://en.wikipedia.org/wiki/Correlation_coefficient)

5.  Mean Average Error
    [MAERR](https://en.wikipedia.org/wiki/Mean_absolute_error)

##### Select learning algorithm {#3.2.03.2.2_learning_algorithm}

Learning algorithm to be used for the **regression** analysis. Each
algorithm has a particular set of parameters that are described in the
respective distributions. In general defaults are provided.

1.  SVM -- [LIBSVM](https://www.csie.ntu.edu.tw/~cjlin/libsvm/)

2.  SVM -- [LIBLINEAR](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)

3.  RVM / BAYES -- [Mike Tipping's
    implementation](http://www.miketipping.com/sparsebayes.htm)

4.  Multinomial relevance vector regression (MVRVR) (for multiple target
    label prediction)

5.  Univariate -- GLM Linear Regression

##### Define kernel type {#3.2.03.2.3_kernel_type}

Kernel to be used in the selected **regressor** (when applicable).

1.  Linear

2.  Polynomial

3.  RBF (Gaussian)

4.  Sigmoid

##### Optimize decision threshold based on ROC {#3.2.03.2.4_optimize decision threshold}

This option allows to optimise the decision scores according to the
Receiver Operator Function.The default setting enables the post-hoc
optimisation using ROC analysis of C1 test data.

##### Use ADASYN to adjust for unbalanced class settings {#3.2.03.2.5_optimize decision threshold}

Adaptive Synthetic (ADASYN) is primarily used to tackle the 'Imbalanced
Classification Problem' prominent in Machine Learning which arises due
to imabalanced class size. The key hindrance with an imbalanced dataset
is that one class dominates another class resulting in a model that is
highly underfitted as it is not able to classify the minority class
successfully. ADASYN is an algorithm that generates synthetic data by
generating more data for the class with lesser data.

Enabling ADASYN mode opens up extra options:\
**7: Define beta value (defines how much balancing will be applied, 0,1)
\[k=1\]**\
**8: Define k value of density algorithm (kNN looking at both classes)
\[k=5\]**\
**9: Define k value of SMOTE algorithm (kNN looking only at the minority
class) \[k=5\]**\
**10: Data is already normalized for kNN search \[no\]**\

#### Sequence Optimization

When in the NeuroMiner \"expert\" mode (i.e., loading NeuroMiner with
the command \"nm nosplash expert\") another option in the \"model
algorithm\" menu is to conduct sequence optimization. This option was
designed to simulate the clinical decision making associated with
additional testing. In a clinical environment, the decision to conduct
another assessment on an individual is normally done in situations of
uncertainty to confirm a diagnosis--e.g., coronavirus is suspected based
on a clinical assessment and then a nasal swab is conducted to confirm
this diagnosis. In a machine learning context, uncertainty can be
quantified with either the distance from the decision boundary in the
case of an SVM (i.e., with cases closest to the decision line being the
most uncertain) or with a median using any other scores.

NeuroMiner is able to test sequences of assessments (e.g., clinical,
cognitive, imaging) based on the modalities entered during data entry or
it is able to build optimal sequences based on different models (e.g.,
linear and non-linear SVM). The pipelines need to have been analysed
before sequencing can be activated. The procedure is to:

1.  Process multiple analyses as usual from different modalities or
    using different settings

2.  In the \"Parameter Template\" menu, activate the option to 1: Define
    meta-learning/stacking options

3.  Select the analyses that you want to define the optimal sequence for

4.  Go to the preprocessing parameters and change the set-up so that
    there is only an imputation step. If you are sequentially stacking
    different learning algorithms, then scaling may be required and this
    needs to be considered

5.  In the \"Parameter Template\" menu, go to the \"Classification
    Algorithm\" option and then the \"Select learning algorithm\" option

6.  Select the item \"SEQOPT ---\> Predictive sequence optimization
    algorithm (Stacking only)\"

7.  To configure the sequence algorithm, then select the option to
    \"Configure Sequence Optimizer\"

##### Optimization based on\...

1.  The population to be propagated

2.  The entire population

NeuroMiner will attempt to optimise two factors: 1) the criterion that
the user decides in the previous step (e.g., BAC); 2) the least number
of assessments necessary. These optimizations can be for only the cases
that have uncertain decision or probability scores (option 1) or for the
entire population.

##### Define computation mode for combining sequential predictions

1.  Replacement

2.  Mean across predictions

When a case is propagated to another assessment because the first
assessment was uncertain, then either their decision score can be
replaced or a mean can be taken across the predictions in the sequence
(i.e., this becomes bagging or \"late fusion\" in NeuroMiner
terminology).

##### Define propagation algorithm's anchor

1.  Decision boundary

2.  Median

As mentioned above, either the decision boundary can be used to define
uncertain cases (i.e., near the boundary) or the median of other scores
can be taken. The first item uses the decision boundary and the second
item uses the median to quantify the uncertainty (i.e., the median of
scores that range from very likely group 1 to very likely group 2 is
assumed to be uncertain here).

##### Define optimisation mode

1.  Optimization criterion

2.  Mean decision distance

Here the user can select whether to optimize on the criterion previously
selected (e.g., the BAC) or on the mean decision distance (only works
for SVM or algorithms with decision scores). In the second case, the
idea is that the further away from the decision boundary the better the
optimization.

##### Sequences to be tested

1.  Define sequences matrix to be evaluated

Here the user can define what sequences are to be evaluated. This step
is dependent on the identification of models to be included in the \"1:
Define meta-learning/stacking options\". The idea is that rather than
testing all combinations of the models (e.g., model 1 -\> model 2 -\>
model 3 and then all other combinations of these), the user can specify
the models that they want to test. This is because usually there is a
rationale for testing model sequences based on clinical experience and
also cost (e.g., clinical assessment, then cognitive assessment, then
imaging if necessary).

Sequences of assessments need to be specified here either directly or
using a matlab variable. For example, if you wanted to specify a
sequence of model 1 -\> model 2 -\> model 3 then you would enter \[1 2
3\]. If you wanted to specify this and also models 2 1 3 then you would
enter \[1 2 3; 2 1 3\]. If you wanted to specify more then you would
create a matlab variable with more sequences in rows and you would enter
the variable name into this section.
