### Learning algorithm parameters {#3.2.04_learning_algorithm_parameters}

Parameters for a learning algorithm (e.g., an SVM or SVR) change the way
that the model is fitted to the data. A common example is the \"C\" or
\"slack\" parameter for soft margin SVM that defines the penalty
associated with misclassifying individuals--i.e., whether the model does
not allow any error within the CV1 folds and very tightly fits the
decision boundary, or whether it allows error in order to improve
generalizability. As such, parameters such as these can greatly affect
the model performance and it is common practice in machine learning to
optimise the parameters for your specific problem and data.

NeuroMiner was developed in order to optimise performance across
pre-defined parameter ranges within the nested cross-validation
framework using a gridsearch, which protects against overfitting due to
the application of the trained models to held-out data. Parameter
default ranges are provied in NeuroMiner based on the literature and
empirical testing, but we strongly recommend that the parameters are
defined for your study and problem.

As previously stated, NeuroMiner uses a dynamic menu configuration that
changes based on previous input. This is no different for the learning
algorithm parameters, whereby the menu options will change based on what
you have selected in the \"Classification algorithm\" section.

Here we show an example for a RBF-Gaussian kernel Support Vector Machine
**classifier**.

1.  [Define Slack/Regularization
    parameter(s)](https://en.wikipedia.org/wiki/Support_vector_machine#Parameter_selection)

2.  [Define Kernel
    parameter(s))](https://en.wikipedia.org/wiki/Support_vector_machine#Parameter_selection)

3.  [Define Weighting
    exponents](https://www.csie.ntu.edu.tw/~cjlin/libsvm/faq.html#f410)

4.  Enable regularization of model selection

Model selection regularization option controls the optimization module
in Neurominer. When parameter(s) selection is necessary regularization
might be advisable. If you answer yes to this question the following
options will be available.

1.  Criterion for cross-parameter model selection

2.  Suboption 1 dependent on (a)

3.  Suboption 2 dependent on (a)

4.  Specify cross-parameter model selection process. This option
    controls the number of models (parameters combination) selected. One
    optimal model based on the criteria and regularization defined
    previously or an ensemble of the top performing models
