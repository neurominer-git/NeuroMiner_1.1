
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Ensemble generation strategies &#8212; NeuroMiner Manual</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Visualization options" href="3.2.06_paramtemp_visualization_options.html" />
    <link rel="prev" title="Learning algorithm parameters" href="3.2.04_paramtemp_learning_algorithm_parameters.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/nm_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NeuroMiner Manual</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Neurominer
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1.0_introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.1_prerequisites.html">
   Suggested Prerequisites
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1.2_gettingstarted.html">
   Installation &amp; Configuration
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  NeuroMiner interface
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="3.0_mainmenu.html">
   Main interface overview
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.1_mainmenu_input_data.html">
   Data entry in NeuroMiner
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="3.2_mainmenu_define_parameter_template.html">
   Define parameter template
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.00_paramtemp_data_fusion.html">
     Data Fusion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.01_paramtemp_cv_settings.html">
     Cross-validation settings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.02_paramtemp_preprocessing_pipeline.html">
     Preprocessing pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.03_paramtemp_classification_algorithm.html">
     Classification algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.04_paramtemp_learning_algorithm_parameters.html">
     Learning algorithm parameters
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Ensemble generation strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.06_paramtemp_visualization_options.html">
     Visualization options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.08_paramtemp_model_saving_options.html">
     Model saving options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.11_paramtemp_inspect_workspace.html">
     Inspect workspace
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.12_paramtemp_save_parameter_template.html">
     Save parameter template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.13_paramtemp_load_training_template.html">
     Load training template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="3.2.15_paramtemp_stacking.html">
     Stacking
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.3_mainmenu_initialize_delete_analyses.html">
   Initialize analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.4_mainmenu_preprocess_features.html">
   Preprocess features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.5_mainmenu_train_supervised_classifiers.html">
   Train supervised classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.6_mainmenu_visualize_classifiers.html">
   Visualize classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.7_mainmenu_display_training_results.html">
   Result Viewer
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.8_mainmenu_OOCV_analysis.html">
   Out of Sample Cross-Validation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.9_mainmenu_load_struct.html">
   Load NeuroMiner structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.10_mainmenu_save_struct.html">
   Save NeuroMiner structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.11_mainmenu_change_wd.html">
   Change working directory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.12_mainmenu_investigate_sample_size.html">
   Investigate sample size (simulation)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3.13_mainmenu_utilities.html">
   Utilities
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="4.0_Example.html">
   Basic usage
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fdocs/3.2.05_paramtemp_ensemble_generation_strategies.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/3.2.05_paramtemp_ensemble_generation_strategies.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filter-based-ensemble-generalization">
   Filter-based ensemble generalization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-filter-methods-on-cv1-partitions">
     1 | Train filter methods on CV1 partitions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-algorithm-output-scores-or-label-predictions">
     2 | Use algorithm output scores or label predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specify-filter-type">
     3 | Specify filter type
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-minimum-number-of-features-to-be-selected">
     4 | Define minimum number of features to be selected
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specify-subspace-optimization-strategy">
     5 | Specify subspace optimization strategy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-target-population-for-computing-optimization-parameter">
     6 | Define target population for computing optimization parameter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-subspace-stepping">
     7 | Define subspace stepping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wrapper-based-model-selection">
   Wrapper-based model selection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wrapper-type">
     4 | Wrapper type
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#greedy-feature-selection">
       Greedy feature selection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#simulated-annealing">
       Simulated annealing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#genetic-algorithm">
       Genetic algorithm
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particle-swarm-optimization">
       Particle swarm optimization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#path-finder-algorithm">
       Path finder algorithm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cv1-data-partitions-for-optimization">
     5 | CV1 data partitions for optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-cv1-feature-selection">
     6 | Cross-CV1 feature selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-feature-extraction">
       Probabilistic feature extraction
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#apply-consistency-based-ranking">
       Apply consistency-based ranking
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Ensemble generation strategies</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#filter-based-ensemble-generalization">
   Filter-based ensemble generalization
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-filter-methods-on-cv1-partitions">
     1 | Train filter methods on CV1 partitions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#use-algorithm-output-scores-or-label-predictions">
     2 | Use algorithm output scores or label predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specify-filter-type">
     3 | Specify filter type
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-minimum-number-of-features-to-be-selected">
     4 | Define minimum number of features to be selected
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#specify-subspace-optimization-strategy">
     5 | Specify subspace optimization strategy
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-target-population-for-computing-optimization-parameter">
     6 | Define target population for computing optimization parameter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-subspace-stepping">
     7 | Define subspace stepping
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#wrapper-based-model-selection">
   Wrapper-based model selection
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#wrapper-type">
     4 | Wrapper type
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#greedy-feature-selection">
       Greedy feature selection
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#simulated-annealing">
       Simulated annealing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#genetic-algorithm">
       Genetic algorithm
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#particle-swarm-optimization">
       Particle swarm optimization
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#path-finder-algorithm">
       Path finder algorithm
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cv1-data-partitions-for-optimization">
     5 | CV1 data partitions for optimization
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cross-cv1-feature-selection">
     6 | Cross-CV1 feature selection
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#probabilistic-feature-extraction">
       Probabilistic feature extraction
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#apply-consistency-based-ranking">
       Apply consistency-based ranking
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="ensemble-generation-strategies">
<span id="paramtemp-ensemble-generation-strategies"></span><h1>Ensemble generation strategies<a class="headerlink" href="#ensemble-generation-strategies" title="Permalink to this headline">#</a></h1>
<p>NeuroMiner automatically works with ensemble learning at the CV2 level across the CV1 folds of a nested, repeated cross-validation design (see <a class="reference internal" href="3.2.01_paramtemp_cv_settings.html#fig-3-2-01-nested-cv"><span class="std std-numref">Fig. 8</span></a>), but it also includes the ability to apply filters and wrappers that optimize predictions by selecting features within these folds (for more information, see <a class="reference external" href="https://en.wikipedia.org/wiki/Ensemble_learning">wiki</a> and <span class="xref myst">Kolhavi &amp; John</span>.</p>
<section id="filter-based-ensemble-generalization">
<h2>Filter-based ensemble generalization<a class="headerlink" href="#filter-based-ensemble-generalization" title="Permalink to this headline">#</a></h2>
<p>NeuroMiner has two methods of applying filters:</p>
<ol class="simple">
<li><p>As part of the preprocessing of features by pre-selecting variables based on their relationship to the target (<a class="reference internal" href="3.2.02_paramtemp_preprocessing_pipeline.html#preproc-rank"><span class="std std-ref">rank/ weight features</span></a>)</p></li>
<li><p>As an ensemble method where different variable sets (variable subspaces) can be chosen based on the performance of the machine learning training algorithm.</p></li>
</ol>
<p>The latter case is known as <strong>constrained feature optimization</strong> because the variable sets are produced based on the performance of an algorithm (e.g., correlation), the sets are evaluated with the algorithm, and then the models corresponding to well-performing variable sets are chosen as an ensemble.</p>
<p>The first step is to turn the option specifying the ”Train filter methods on CV1 partitions” to “yes”. This will generate the following menu:</p>
<figure class="align-default" id="fig-nm-ensemble-filterbased">
<img alt="Neurominer ensemble generalization filter based" src="../_images/NM_ensemble_filterbased.png" />
</figure>
<section id="train-filter-methods-on-cv1-partitions">
<h3>1 | Train filter methods on CV1 partitions<a class="headerlink" href="#train-filter-methods-on-cv1-partitions" title="Permalink to this headline">#</a></h3>
<p>Turn constrained feature optimization filtering on or off.</p>
</section>
<section id="use-algorithm-output-scores-or-label-predictions">
<h3>2 | Use algorithm output scores or label predictions<a class="headerlink" href="#use-algorithm-output-scores-or-label-predictions" title="Permalink to this headline">#</a></h3>
<p>Choose the feature sets based on majority voting of the predicted labels (hard decision ensemble) or based on an average of the predicted probabilities from the machine learning algorithm (soft decision ensemble).</p>
</section>
<section id="specify-filter-type">
<h3>3 | Specify filter type<a class="headerlink" href="#specify-filter-type" title="Permalink to this headline">#</a></h3>
<p>Specify what filter will be used to obtain the feature sets. These methods are the same as in the <a class="reference internal" href="3.2.02_paramtemp_preprocessing_pipeline.html#preproc-rank"><span class="std std-ref">preprocessing filter</span></a>.</p>
</section>
<section id="define-minimum-number-of-features-to-be-selected">
<h3>4 | Define minimum number of features to be selected<a class="headerlink" href="#define-minimum-number-of-features-to-be-selected" title="Permalink to this headline">#</a></h3>
<p>This gives the option to define a minimum number of features that are retained when choosing feature sets.</p>
</section>
<section id="specify-subspace-optimization-strategy">
<h3>5 | Specify subspace optimization strategy<a class="headerlink" href="#specify-subspace-optimization-strategy" title="Permalink to this headline">#</a></h3>
<p>Once the subspaces are defined and the models are evaluated, this section will define which subspaces/models are retained. There is the option to retain one model of the best performing subspace, or an ensemble of models across well-performing subspaces.</p>
<blockquote>
<div><p><strong>1 | Subspace with maximum argmax</strong>: Argmax (arguments of the maxima) are the points of the domain of some function at which the function values are maximized. This option picks the maximum argmax across the feature subspaces (winner-takes-it-all).</p>
<p><strong>2 | Subspace ensemble with maximum argmax</strong>: Picks the X most predictive subspaces with reference to the argmax.</p>
<p><strong>3 | Subspace ensemble with maximum argmax above a percentile</strong> Picks the top X% of subspaces.</p>
<p><strong>4 | All-subspace ensemble</strong>: Uses all subspaces when training the model.</p>
</div></blockquote>
<p>Provided that an ensemble-based method is selected as the subspace selection strategy  (options 2-4), an additional menu entry (<strong>2 | Define ensemble optimization method</strong>) allows you to choose the ensemble optimization method from one of the following, essentially referring to the way in which you want the base models generated for each feature subspace to be combined:</p>
<figure class="align-default" id="fig-nm-filter-subspace-ensemble-options">
<img alt="NeuroMiner filters subspace-based ensemble optimization menu" src="../_images/NM_filter_subspace_ensemble_options.png" />
</figure>
<blockquote>
<div><p><strong>1 | Simply aggregate all learners into ensemble</strong>: This is also known as bagging and consists of averaging across the base learners trained independently in parallel.</p>
<p><strong>2 | Optimize ensemble using backward base learner elimination</strong>: This uses a greedy search algorithm in order to find an optimal subset of base learners by backward search, such that all base learners are initially included and then learners are recursively removed in order to achieve an optimal solution. The optimization can be done based on different criteria (default: Entropy &amp; Performance, Entropy of ensemble’s component models, Kappa-Diversity among ensemble’s component decisions or Bias-Variance decomposition of ensemble’s component errors). Either the algorithm output scores (soft ensemble) or the label predictions (hard ensemble) can be used in order to construct the ensemble. Moreover, you can specify a minimum number of base learners to be included in the ensemble and enable weigthing of the base learners based on the inverse of their error. This opens a sub-menu to further specify additional parameters:</p>
</div></blockquote>
<figure class="align-default" id="fig-nm-filter-backward-base-learner-elim">
<img alt="NeuroMiner filters subspace-based ensemble optimization menu" src="../_images/NM_filter_backward_base_learner_elim.png" />
</figure>
<blockquote>
<div><p><strong>3 | Optimize ensemble using forward base learner selection</strong>: This uses a greedy search algorithm in order to find an optimal subset of base learners by forward search, such that initially only one base learner is included and then learners are recursively added in order to achieve an optimal solution. The other settings are similar to those described for the backward base learner elimination.</p>
<p><strong>4 | Create a single classifier using probabilistic feature subspace construction</strong>: This option selects the optimal feature subspaces based on the agreement across the different base learners for each specific feature. For this, you need to specify a threshold for the percentage of times that a feature is selected across CV1 feature subspaces and only the features above this threshold will be used to build the ensemble classifier.</p>
<p><strong>5 | Use AdaBoost to determine optimal weighting of base learners</strong>: Here, the popular boosting algorithm AdaBoost is used in order to compute a weighted majority vote of the weak hypotheses generated by the weak learners. More details on how the AdaBoost algorithm works can be found in Freund, Y., &amp; Schapire, R. E. (1997) or Schapire, R. E. (2013).</p>
<p><strong>6 | Define target population for computing optimization parameter</strong>: You can choose the best performing models using the CV1 training data, the CV1 test data, or the CV1 training &amp; the test data. This means that the subspaces will be selected on the basis of how they predict the labels in each of these data folds. Selection based on training and test data is recommended.</p>
<p><strong>7 | Define subspace stepping</strong>: This option defines how the subspaces are formed. The features are ranked based on the association between them and the target variable, and then they are divided into subspaces based on blocks of X% of features; e.g., blocks of 10% of features would divide the data into the top 10% performing features, then the top 20% of features, then the top 30% of features, and so on.</p>
</div></blockquote>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is important to note that once the feature subspaces are defined, the features within the winning subspaces can then be used in a wrapper to further optimize performance.</p>
</div>
</section>
<section id="define-target-population-for-computing-optimization-parameter">
<h3>6 | Define target population for computing optimization parameter<a class="headerlink" href="#define-target-population-for-computing-optimization-parameter" title="Permalink to this headline">#</a></h3>
<p>You can choose the best performing models using the CV1 training data, the CV1 test data, or the CV1 training &amp; the test data. This means that the subspaces will be selected on the basis of how they predict the labels in each of these data folds. Selection based on training and test data is recommended.</p>
</section>
<section id="define-subspace-stepping">
<h3>7 | Define subspace stepping<a class="headerlink" href="#define-subspace-stepping" title="Permalink to this headline">#</a></h3>
<p>This option defines how the subspaces are formed. The features are ranked based on the association between them and the target variable, and then they are divided into subspaces based on blocks of X% of features; e.g., blocks of 10% of features would divide the data into the top 10% performing features, then the top 20% of features, then the top 30% of features, and so on.
It is important to note that once the feature subspaces are defined, the features within the winning subspaces can then be used in a wrapper to further optimize performance.</p>
</section>
</section>
<hr class="docutils" />
<section id="wrapper-based-model-selection">
<h2>Wrapper-based model selection<a class="headerlink" href="#wrapper-based-model-selection" title="Permalink to this headline">#</a></h2>
<p>The wrapper methods in NeuroMiner use either Greedy feature selection or simulated annealing to select feature combinations that maximize the predictive accuracy of a model in the CV1 data. You will see the following menu:</p>
<figure class="align-default" id="fig-nm-ensemble-wrapperbased">
<img alt="Neurominer ensemble generalization wrapper based" src="../_images/NM_ensemble_wrapperbased.png" />
</figure>
<section id="wrapper-type">
<h3>4 | Wrapper type<a class="headerlink" href="#wrapper-type" title="Permalink to this headline">#</a></h3>
<figure class="align-default" id="fig-nm-ensemble-wrappertypes">
<img alt="Neurominer ensemble generalization wrapper types" src="../_images/NM_ensemble_wrappertypes.png" />
</figure>
<p>Select greedy feature selection or simulated annealing.</p>
<section id="greedy-feature-selection">
<h4>Greedy feature selection<a class="headerlink" href="#greedy-feature-selection" title="Permalink to this headline">#</a></h4>
<blockquote>
<div><p>1 | Search direction [ Forward ]</p>
<p>2 | Early stopping [ Stop at 50% of feature pool ]</p>
<p>3 | Feature stepping [ Each feature will be evaluated ]</p>
<p>4 | Kneepoint-based threshold detection  [ disabled ]</p>
</div></blockquote>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Greedy_algorithm">Greedy feature selection</a> aims to find the best subset of features by iteratively adding/ excluding features. This means that at each step, the algorithm chooses the features that improve the performance at this stage, i.e., the algorithm makes a local optimal choice and may, thus, not end up at a global optimum.</p>
<p>The “search direction” must be provided (forward or backward), which determines whether an empty subspace is filled with features that are the most predictive of the target variable (forward selection) or whether all the variables are entered into the subspace and then variables are removed until the optimal model is found (backward).</p>
<p>If you enable “early stopping”, a defined percentage of variables is remaining in the feature pool, i.e., when this percentage is reached no more variables are added to the analysis. This setting is useful when you want to find parsimonious solutions and restricting the features to be included can lead to better solutions.</p>
<p>“Feature stepping” can also be changed from adding/removing single features and then testing the model, or adding/removing percentages of the remaining features before testing the model. Adding percentages (e.g., 5%) normally results in a faster processing time.</p>
</section>
<section id="simulated-annealing">
<h4>Simulated annealing<a class="headerlink" href="#simulated-annealing" title="Permalink to this headline">#</a></h4>
<figure class="align-default" id="fig-nm-ensemble-simulatedannealing">
<img alt="Neurominer ensemble simulated annealing" src="../_images/NM_wrapper_simulatedannealing.png" />
</figure>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Simulated_annealing">Simulated annealing</a> is a probabilistic technique for approximating the global maximum of a function. The settings are standard parameters for any simulated annealing analysis.</p>
</section>
<section id="genetic-algorithm">
<h4>Genetic algorithm<a class="headerlink" href="#genetic-algorithm" title="Permalink to this headline">#</a></h4>
<p>A genetic algorithm tries to find the best feature selection method following strategies similar to natural selection in evolution. You can specify the following parameters (see the linked paper for more details):</p>
<figure class="align-default" id="fig-nm-ensemble-geneticalgorithms">
<img alt="Neurominer ensemble genetic algorithms" src="../_images/NM_wrapper_geneticalgorithms.png" />
</figure>
</section>
<section id="particle-swarm-optimization">
<h4>Particle swarm optimization<a class="headerlink" href="#particle-swarm-optimization" title="Permalink to this headline">#</a></h4>
<p><a class="reference external" href="https://doi.org/10.1162/EVCO_r_00180">particle swarm optimization algorithm</a> is based on the behavior of birds. It has the following parameters:</p>
<figure class="align-default" id="fig-nm-ensemble-particleswarm">
<img alt="Neurominer ensemble particle swarm" src="../_images/NM_wrapper_particleswarm.png" />
</figure>
</section>
<section id="path-finder-algorithm">
<h4>Path finder algorithm<a class="headerlink" href="#path-finder-algorithm" title="Permalink to this headline">#</a></h4>
<p>The path finder algorithm has the following parameters:</p>
<figure class="align-default" id="fig-nm-ensemble-pathfinder">
<img alt="Neurominer ensemble path finder" src="../_images/NM_wrapper_pathfinder.png" />
</figure>
</section>
</section>
<section id="cv1-data-partitions-for-optimization">
<h3>5 | CV1 data partitions for optimization<a class="headerlink" href="#cv1-data-partitions-for-optimization" title="Permalink to this headline">#</a></h3>
<p>Choose either the CV1 training, test, or test &amp; training data to optimize the feature set.</p>
</section>
<section id="cross-cv1-feature-selection">
<h3>6 | Cross-CV1 feature selection<a class="headerlink" href="#cross-cv1-feature-selection" title="Permalink to this headline">#</a></h3>
<p>In a nested cross-validation design, you will have a selection of features for each of the CV1 partitions. This step allows you to select features across the CV1 folds and will reveal another menu:</p>
<blockquote>
<div><p>1 | Optimize feature selection across CV1 partitions [ yes ]</p>
<p>2 | Probabilistic feature extraction mode [% Cross-CV1 feature selection agreement ]</p>
<p>3 | Apply consistency-based ranking to [ Prune unselected features from each model and retrain models ]</p>
</div></blockquote>
<section id="probabilistic-feature-extraction">
<h4>Probabilistic feature extraction<a class="headerlink" href="#probabilistic-feature-extraction" title="Permalink to this headline">#</a></h4>
<blockquote>
<div><p>1 | Cross-CV1 feature selection agreement with tolerance window</p>
<p>2 | Absolute number of most consistently selected features</p>
<p>3 | Percentage of most consistently selected features</p>
</div></blockquote>
<p><strong>Cross-CV1 feature selection agreement with tolerance window</strong>
This option allows you to select features that occur across CV1 partitions at a certain percentage rate. For example, select only features that appear across CV1 folds 75% of the time or more. Sometimes the threshold that is set does not return any features, and therefore you will also be asked to define a tolerance value for this circumstance. For example, if the 75% criterion is not met, then reduce this by 25% (i.e., so then you are effectively selecting features 50% of the time). You will also be asked to define a minimum number of features that must be selected each time (e.g., one feature).</p>
<p><strong>Absolute number of most consistently selected features</strong>
This option orders the features based on the amount of times they were selected across the CV1 folds. Then you can select the number of features occurring at the top of the list (e.g., you could select the top 10 most consistently selected features).</p>
<p><strong>Percentage of most consistently selected features</strong>
This option sorts in the same way as described for absolute number of consistently selected features and then establishes a cut-off. The features above this cut-off are kept. For example, if 90% is the cut-off then it will select the top 10% of the most consistently selected features across the CV1 folds.</p>
</section>
<section id="apply-consistency-based-ranking">
<h4>Apply consistency-based ranking<a class="headerlink" href="#apply-consistency-based-ranking" title="Permalink to this headline">#</a></h4>
<blockquote>
<div><p>1 | Retrain all CV1 models after pruning them from unselected features</p>
<p>2 | Retrain all CV1 models using the same selected feature space</p>
</div></blockquote>
<p>Once the features are selected, you can either ”1 | Retrain all CV1 models” after pruning the unselected features. Or you can completely retrain the models using the single optimized feature set that was found in the previous steps.</p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="3.2.04_paramtemp_learning_algorithm_parameters.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Learning algorithm parameters</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="3.2.06_paramtemp_visualization_options.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Visualization options</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Neurodiagnostics Lab LMU Munich<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>